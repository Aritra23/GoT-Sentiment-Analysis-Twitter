{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lahir\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lahir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "from tweepy import Stream\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from sqlalchemy import func\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np  \n",
    "import re  \n",
    "import nltk  \n",
    "from sklearn.datasets import load_files  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "nltk.download('stopwords')\n",
    "import pickle  \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"data/combined.csv\"\n",
    "df = pd.read_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to combine the CVS files and then include a column 'isalive'\n",
    "# For the given date, the corresponding corresponding character will have 0 - Alive or 1 - Dead\n",
    "df[\"isalive\"] = \"0\"\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"char\"] == \"Arya Stark\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Bran Stark\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Brienne of Tarth\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Cersei Lannister\" :\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "        else:\n",
    "            df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Daenerys Targaryen\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Euron Greyjoy\":\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "    if row[\"char\"] == \"Jaime Lannister\":\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "    if row[\"char\"] == \"Jon Snow\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Missandei\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Sandor Clegane (“The Hound”)\":\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "    if row[\"char\"] == \"Sansa Stark\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Theon Greyjoy\":\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "    if row[\"char\"] == \"Tyrion Lannister\":\n",
    "        df.loc[index, \"isalive\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8181818181818182\n",
      "Testing Data Score: 0.75\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1a4742534eef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Training Data Score: {classifier.score(X_train, y_train)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Testing Data Score: {classifier.score(X_test, y_test)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Prediction\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Actual\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "df_backup = df\n",
    "df = df_backup\n",
    "df2 = df.groupby([\"char\", \"date\", \"isalive\"]).agg({\"polarity\" : \"mean\", \"subjectivity\" : \"mean\"})\n",
    "df = df2.reset_index()\n",
    "df3 = pd.DataFrame()\n",
    "df3[\"char\"] = [char for char in df[\"char\"]]\n",
    "df3[\"date\"] = [date for date in df[\"date\"]]\n",
    "df3[\"isalive\"] = [isalive for isalive in df[\"isalive\"]]\n",
    "df3[\"polarity\"] = [polarity for polarity in df[\"polarity\"]]\n",
    "df3[\"subjectivity\"] = [subjectivity for subjectivity in df[\"subjectivity\"]]\n",
    "df = df3\n",
    "df1 = df.loc[(df[\"date\"] == \"05/11/2019\") | (df[\"date\"] == \"05/12/2019\")]\n",
    "y = df1[\"isalive\"]\n",
    "X = []\n",
    "for index, row in df1.iterrows():\n",
    "   x = []\n",
    "   x.append(row[\"polarity\"])\n",
    "   x.append(row[\"subjectivity\"])\n",
    "   X.append(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y, test_size=0.5)    \n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")\n",
    "# pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = \"data/DaenerysTargaryen_19_21.csv\"\n",
    "new_df = pd.read_csv(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>char</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @RotoRadarCEO: The #GameOfThronesFinale is ...</td>\n",
       "      <td>05/19/2019</td>\n",
       "      <td>Daenerys Targaryen</td>\n",
       "      <td>Neu</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>05/19/2019 23:59:55</td>\n",
       "      <td>rt rotoradarceo the gameofthronesfinale is upo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RotoRadarCEO: The #GameOfThronesFinale is ...</td>\n",
       "      <td>05/19/2019</td>\n",
       "      <td>Daenerys Targaryen</td>\n",
       "      <td>Neu</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>05/19/2019 23:59:51</td>\n",
       "      <td>rt rotoradarceo the gameofthronesfinale is upo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @oshawildling: daenerys targaryen’s journey...</td>\n",
       "      <td>05/19/2019</td>\n",
       "      <td>Daenerys Targaryen</td>\n",
       "      <td>Pos</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.6</td>\n",
       "      <td>05/19/2019 23:59:50</td>\n",
       "      <td>rt oshawildling daenerys targaryen journey wa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @mviser: Pete Buttigieg on Daenerys Targary...</td>\n",
       "      <td>05/19/2019</td>\n",
       "      <td>Daenerys Targaryen</td>\n",
       "      <td>Neg</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05/19/2019 23:59:45</td>\n",
       "      <td>rt mviser pete buttigieg on daenerys targaryen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my brave girl who survived against all odds. w...</td>\n",
       "      <td>05/19/2019</td>\n",
       "      <td>Daenerys Targaryen</td>\n",
       "      <td>Pos</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05/19/2019 23:59:43</td>\n",
       "      <td>my brave girl who survived against all odds wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        date  \\\n",
       "0  RT @RotoRadarCEO: The #GameOfThronesFinale is ...  05/19/2019   \n",
       "1  RT @RotoRadarCEO: The #GameOfThronesFinale is ...  05/19/2019   \n",
       "2  RT @oshawildling: daenerys targaryen’s journey...  05/19/2019   \n",
       "3  RT @mviser: Pete Buttigieg on Daenerys Targary...  05/19/2019   \n",
       "4  my brave girl who survived against all odds. w...  05/19/2019   \n",
       "\n",
       "                 char sentiment  polarity  subjectivity            timestamp  \\\n",
       "0  Daenerys Targaryen       Neu    0.0000           0.1  05/19/2019 23:59:55   \n",
       "1  Daenerys Targaryen       Neu    0.0000           0.1  05/19/2019 23:59:51   \n",
       "2  Daenerys Targaryen       Pos    0.1125           0.6  05/19/2019 23:59:50   \n",
       "3  Daenerys Targaryen       Neg   -0.5000           1.0  05/19/2019 23:59:45   \n",
       "4  Daenerys Targaryen       Pos    0.8250           1.0  05/19/2019 23:59:43   \n",
       "\n",
       "                                          Preprocess  \n",
       "0  rt rotoradarceo the gameofthronesfinale is upo...  \n",
       "1  rt rotoradarceo the gameofthronesfinale is upo...  \n",
       "2  rt oshawildling daenerys targaryen journey wa ...  \n",
       "3  rt mviser pete buttigieg on daenerys targaryen...  \n",
       "4  my brave girl who survived against all odds wh...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"isalive\"] = \"0\"\n",
    "for index, row in new_df.iterrows():\n",
    "    if row[\"char\"] == \"Daenerys Targaryen\":\n",
    "         if row[\"date\"] == \"05/20/2019\" \\\n",
    "            or row[\"date\"] == \"05/21/2019\":\n",
    "            new_df.loc[index, \"isalive\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-193dc8d563ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"05/20/2019\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_df2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"polarity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1478\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1866\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1867\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1868\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1869\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1491\u001b[0m             \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1493\u001b[1;33m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1494\u001b[0m         \u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(ax, key)\u001b[0m\n\u001b[0;32m   2354\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2356\u001b[1;33m             raise IndexingError('Unalignable boolean Series provided as '\n\u001b[0m\u001b[0;32m   2357\u001b[0m                                 \u001b[1;34m'indexer (index of the boolean Series and of '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2358\u001b[0m                                 'the indexed object do not match')\n",
      "\u001b[1;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match"
     ]
    }
   ],
   "source": [
    "new_df2 = new_df.loc[df[\"date\"] == \"05/19/2019\"]\n",
    "new_data = []\n",
    "for index, row in new_df2.iterrows():\n",
    "    x = []\n",
    "    x.append(row[\"polarity\"])\n",
    "    x.append(row[\"subjectivity\"])\n",
    "    new_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df1 = df.loc[(df[\"date\"] == \"05/11/2019\") | (df[\"date\"] == \"05/12/2019\")]\n",
    "y = [y for y in df1[\"isalive\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for index, row in df1.iterrows():\n",
    "    x = []\n",
    "    x.append(row[\"polarity\"])\n",
    "    x.append(row[\"subjectivity\"])\n",
    "    X.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6519211682971785\n",
      "Testing Data Score: 0.6518287496455911\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f0ca3f801cbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Prediction\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Actual\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df.loc[(df[\"date\"] != \"05/11/2019\") & (df[\"date\"] != \"05/12/2019\")]\n",
    "df2 = df.loc[df[\"date\"] == \"05/19/2019\"]\n",
    "new_data = []\n",
    "for index, row in df2.iterrows():\n",
    "    x = []\n",
    "    x.append(row[\"polarity\"])\n",
    "    x.append(row[\"subjectivity\"])\n",
    "    new_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(new_data)\n",
    "pred_df = pd.DataFrame({\"Prediction\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[\"Prediction\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = \"data/BranStark_11_19.csv\"\n",
    "new_df = pd.read_csv(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"isalive\"] = \"\"\n",
    "for index, row in new_df.iterrows():\n",
    "    if row[\"char\"] == \"Bran Stark\":\n",
    "        new_df.loc[index, \"isalive\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1 = new_df.loc[(new_df[\"date\"] == \"05/17/2019\") | (new_df[\"date\"] == \"05/18/2019\")]\n",
    "y1 = [y1 for y1 in new_df1[\"isalive\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>char</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Preprocess</th>\n",
       "      <th>isalive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@JCBOYD_SPORT360 Bran Stark</td>\n",
       "      <td>05/18/2019</td>\n",
       "      <td>Bran Stark</td>\n",
       "      <td>Neg</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>05/18/2019 23:57:42</td>\n",
       "      <td>jcboyd_sport360 bran stark</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bran Stark on the iron throne.....</td>\n",
       "      <td>05/18/2019</td>\n",
       "      <td>Bran Stark</td>\n",
       "      <td>Neg</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>05/18/2019 23:49:11</td>\n",
       "      <td>bran stark on the iron throne</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@GabyMeza8 @StellaArtoisMx 1.- Bran Stark.\\r\\n...</td>\n",
       "      <td>05/18/2019</td>\n",
       "      <td>Bran Stark</td>\n",
       "      <td>Neg</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>05/18/2019 23:43:19</td>\n",
       "      <td>gabymeza8 stellaartoismx 1 bran stark 2 crzy_af</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@PantherFan87 @thronesfacts @esquire I followe...</td>\n",
       "      <td>05/18/2019</td>\n",
       "      <td>Bran Stark</td>\n",
       "      <td>Neu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05/18/2019 23:43:17</td>\n",
       "      <td>pantherfan87 thronesfacts esquire followed the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bran Stark #GameofThrones https://t.co/KeVhTqbfPu</td>\n",
       "      <td>05/18/2019</td>\n",
       "      <td>Bran Stark</td>\n",
       "      <td>Neg</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>05/18/2019 23:36:16</td>\n",
       "      <td>bran stark gameofthrones http co kevhtqbfpu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        date        char  \\\n",
       "0                        @JCBOYD_SPORT360 Bran Stark  05/18/2019  Bran Stark   \n",
       "1                 Bran Stark on the iron throne.....  05/18/2019  Bran Stark   \n",
       "2  @GabyMeza8 @StellaArtoisMx 1.- Bran Stark.\\r\\n...  05/18/2019  Bran Stark   \n",
       "3  @PantherFan87 @thronesfacts @esquire I followe...  05/18/2019  Bran Stark   \n",
       "4  Bran Stark #GameofThrones https://t.co/KeVhTqbfPu  05/18/2019  Bran Stark   \n",
       "\n",
       "  sentiment  polarity  subjectivity            timestamp  \\\n",
       "0       Neg      -0.2           0.6  05/18/2019 23:57:42   \n",
       "1       Neg      -0.2           0.6  05/18/2019 23:49:11   \n",
       "2       Neg      -0.2           0.6  05/18/2019 23:43:19   \n",
       "3       Neu       0.0           0.0  05/18/2019 23:43:17   \n",
       "4       Neg      -0.2           0.6  05/18/2019 23:36:16   \n",
       "\n",
       "                                          Preprocess isalive  \n",
       "0                         jcboyd_sport360 bran stark       0  \n",
       "1                      bran stark on the iron throne       0  \n",
       "2    gabymeza8 stellaartoismx 1 bran stark 2 crzy_af       0  \n",
       "3  pantherfan87 thronesfacts esquire followed the...       0  \n",
       "4        bran stark gameofthrones http co kevhtqbfpu       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2 = new_df.loc[(new_df[\"date\"] == \"05/17/2019\") | (new_df[\"date\"] == \"05/18/2019\")]\n",
    "new_data = []\n",
    "for index, row in new_df2.iterrows():\n",
    "    x = []\n",
    "    x.append(row[\"polarity\"])\n",
    "    x.append(row[\"subjectivity\"])\n",
    "    new_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(X_test)\n",
    "preds_df = pd.DataFrame({\"Prediction\": preds, \"Actual\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7033</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7034</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7035</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7036</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7037</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7043</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7044</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7045</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7047</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7048</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7050</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7052</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7053</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7054 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction Actual\n",
       "0             0      0\n",
       "1             0      0\n",
       "2             0      1\n",
       "3             0      0\n",
       "4             0      0\n",
       "5             0      0\n",
       "6             0       \n",
       "7             0      0\n",
       "8             0      1\n",
       "9             0      1\n",
       "10            0      0\n",
       "11            0      1\n",
       "12            0      1\n",
       "13            0      0\n",
       "14            0       \n",
       "15            0      0\n",
       "16            0      0\n",
       "17            0      0\n",
       "18            0      0\n",
       "19            0      0\n",
       "20            0      0\n",
       "21            0      0\n",
       "22            0      1\n",
       "23            0       \n",
       "24            0      0\n",
       "25            0      0\n",
       "26            0      0\n",
       "27            0      0\n",
       "28            0      0\n",
       "29            0      0\n",
       "...         ...    ...\n",
       "7024          0      0\n",
       "7025          0      0\n",
       "7026          0      0\n",
       "7027          0      0\n",
       "7028          0      0\n",
       "7029          0      0\n",
       "7030          0      0\n",
       "7031          0       \n",
       "7032          0      1\n",
       "7033          0       \n",
       "7034          0       \n",
       "7035          0      1\n",
       "7036          0      1\n",
       "7037          0      1\n",
       "7038          0      1\n",
       "7039          0      0\n",
       "7040          0      0\n",
       "7041          0      0\n",
       "7042          0      0\n",
       "7043          0      0\n",
       "7044          0      0\n",
       "7045          0      1\n",
       "7046          0      0\n",
       "7047          0      0\n",
       "7048          0       \n",
       "7049          0       \n",
       "7050          0       \n",
       "7051          0      0\n",
       "7052          0      0\n",
       "7053          0      0\n",
       "\n",
       "[7054 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"]\n",
    "y = df[\"isalive\"]\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = tfidfconverter.fit_transform([i for i in df[\"isalive\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = df[\"isalive\"]\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = tfidfconverter.fit_transform(df[\"polarity\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=500, random_state=0)  \n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df1[\"date\"], df1[\"polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "# Define the 'classDB' database in Mongo\n",
    "db = client.projDB\n",
    "char_collection = db.char_img.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name_img_list = []\n",
    "for char in char_collection:\n",
    "    char_dict = {}\n",
    "    char_dict[\"name\"] = char[\"name\"]\n",
    "    char_dict[\"img_url\"] = char[\"img_url\"]\n",
    "    char_name_img_list.append(char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"data/khaleesi.csv\"\n",
    "df1 = pd.read_csv(file1)\n",
    "df = df1[[\"char\", \"date\", \"polarity\"]]\n",
    "df[\"char\"] = \"Daenerys Targaryen\"    \n",
    "df2 = df.groupby([\"char\", \"date\"])[\"polarity\"].mean()\n",
    "file_df = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df.loc[file_df[\"char\"] == \"Daenerys Targaryen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character in char_name_img_list:\n",
    "    print (character[\"name\"])\n",
    "    char_data_df = file_df.loc[file_df[\"char\"] == character[\"name\"]]\n",
    "    print(char_data_df.size)\n",
    "    if char_data_df.size > 0:\n",
    "        character[\"date\"] = [date for date in char_data_df[\"date\"]]\n",
    "        character[\"polarity\"] = [polarity for polarity in char_data_df[\"polarity\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name_img_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
